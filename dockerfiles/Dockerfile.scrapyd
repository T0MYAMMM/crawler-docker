FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    curl \
    vim \
    && rm -rf /var/lib/apt/lists/*

# Install Scrapyd and dependencies
RUN pip install scrapyd scrapyd-client

# Set working directory
WORKDIR /app

# Copy requirements and install
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy crawler project
COPY . .

# Create scrapyd directories
RUN mkdir -p /app/logs /app/eggs /app/dbs /app/items

# Copy scrapyd configuration
COPY scrapyd.conf /etc/scrapyd/scrapyd.conf

# Create non-root user
RUN useradd -m -u 1000 scrapyd && \
    chown -R scrapyd:scrapyd /app
USER scrapyd

# Set environment variables
ENV PYTHONPATH=/app
ENV SCRAPY_SETTINGS_MODULE=scrapy_crawler.settings

# Expose Scrapyd port
EXPOSE 6800

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:6800/daemonstatus.json || exit 1

# Start Scrapyd
CMD ["scrapyd"] 